{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import zipfile\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nzip_file = zipfile.ZipFile('archive.zip')\\ndfs = {text_file.filename: pd.read_csv(zip_file.open(text_file.filename))\\n       for text_file in zip_file.infolist()\\n       if text_file.filename.endswith('.csv')}\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('archive/phishing_email.csv')\n",
    "\n",
    "'''\n",
    "zip_file = zipfile.ZipFile('archive.zip')\n",
    "dfs = {text_file.filename: pd.read_csv(zip_file.open(text_file.filename))\n",
    "       for text_file in zip_file.infolist()\n",
    "       if text_file.filename.endswith('.csv')}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_combined</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hpl nom may 25 2001 see attached file hplno 52...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nom actual vols 24 th forwarded sabrae zajac h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>enron actuals march 30 april 1 201 estimated a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hpl nom may 30 2001 see attached file hplno 53...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hpl nom june 1 2001 see attached file hplno 60...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       text_combined  label\n",
       "0  hpl nom may 25 2001 see attached file hplno 52...      0\n",
       "1  nom actual vols 24 th forwarded sabrae zajac h...      0\n",
       "2  enron actuals march 30 april 1 201 estimated a...      0\n",
       "3  hpl nom may 30 2001 see attached file hplno 53...      0\n",
       "4  hpl nom june 1 2001 see attached file hplno 60...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_combined</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hpl nom may 25 2001 see attached file hplno 52...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nom actual vols 24 th forwarded sabrae zajac h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>enron actuals march 30 april 1 201 estimated a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hpl nom may 30 2001 see attached file hplno 53...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hpl nom june 1 2001 see attached file hplno 60...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82481</th>\n",
       "      <td>info advantageapartmentscom infoadvantageapart...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82482</th>\n",
       "      <td>monkeyorg helpdeskmonkeyorg monkeyorg hi josep...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82483</th>\n",
       "      <td>help center infohelpcentercoza_infohelpcenterc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82484</th>\n",
       "      <td>metamask infosofamekarcom verify metamask wall...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82485</th>\n",
       "      <td>fastway infofastwaycoza_infofastwaycoza_infofa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82486 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           text_combined  label\n",
       "0      hpl nom may 25 2001 see attached file hplno 52...      0\n",
       "1      nom actual vols 24 th forwarded sabrae zajac h...      0\n",
       "2      enron actuals march 30 april 1 201 estimated a...      0\n",
       "3      hpl nom may 30 2001 see attached file hplno 53...      0\n",
       "4      hpl nom june 1 2001 see attached file hplno 60...      0\n",
       "...                                                  ...    ...\n",
       "82481  info advantageapartmentscom infoadvantageapart...      1\n",
       "82482  monkeyorg helpdeskmonkeyorg monkeyorg hi josep...      1\n",
       "82483  help center infohelpcentercoza_infohelpcenterc...      1\n",
       "82484  metamask infosofamekarcom verify metamask wall...      1\n",
       "82485  fastway infofastwaycoza_infofastwaycoza_infofa...      1\n",
       "\n",
       "[82486 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_combined</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hpl nom may 25 2001 see attached file hplno 52...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nom actual vols 24 th forwarded sabrae zajac h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>enron actuals march 30 april 1 201 estimated a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hpl nom may 30 2001 see attached file hplno 53...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hpl nom june 1 2001 see attached file hplno 60...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       text_combined  label\n",
       "0  hpl nom may 25 2001 see attached file hplno 52...      0\n",
       "1  nom actual vols 24 th forwarded sabrae zajac h...      0\n",
       "2  enron actuals march 30 april 1 201 estimated a...      0\n",
       "3  hpl nom may 30 2001 see attached file hplno 53...      0\n",
       "4  hpl nom june 1 2001 see attached file hplno 60...      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>82486.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.519979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.499604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label\n",
       "count  82486.000000\n",
       "mean       0.519979\n",
       "std        0.499604\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        1.000000\n",
       "75%        1.000000\n",
       "max        1.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(408)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text_combined    0\n",
       "label            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82486, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(42845)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['label']==1].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(39233)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['label']==0].value_counts().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = df['text_combined'].astype(str)\n",
    "email_all = \" \".join(emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#email_all_cloud = WordCloud().generate(email_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nplt.figure(figsize=(10, 8))\\nplt.imshow(email_all_cloud, interpolation='bilinear')\\nplt.axis('off')\\nplt.title('Word Cloud of all Emails')\\nplt.show()\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(email_all_cloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud of all Emails')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_emails = df[df['label']==1]['text_combined'].astype(str)\n",
    "spam_emails_all = \" \".join(spam_emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spam_emails_all_cloud = WordCloud().generate(spam_emails_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nplt.figure(figsize=(10, 8))\\nplt.imshow(spam_emails_all_cloud, interpolation='bilinear')\\nplt.axis('off')\\nplt.title('Word Cloud of Spam Emails')\\nplt.show()\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(spam_emails_all_cloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud of Spam Emails')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_emails = df[df['label']==0]['text_combined'].astype(str)\n",
    "clean_emails_all = \" \".join(clean_emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_emails_all_cloud = WordCloud().generate(clean_emails_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nplt.figure(figsize=(10, 8))\\nplt.imshow(clean_emails_all_cloud, interpolation='bilinear')\\nplt.axis('off')\\nplt.title('Word Cloud of Clean Emails')\\nplt.show()\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(clean_emails_all_cloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud of Clean Emails')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\arasekin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\arasekin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\arasekin\\AppData\\Local\\Temp\\ipykernel_5160\\1255572155.py:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  '''\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\ndef text_preprocess(ds: pd.Series) -> pd.Series:\\n    ds = ds.str.lower()\\n    ds = ds.str.replace(r'[^a-zA-Z\\\\s]+', '', regex=True)\\n    ds = ds.str.split()\\n    ds = ds.apply(lambda x: [word for word in x if word not in stopwords.words('english')])\\n    lemmatizer = WordNetLemmatizer()\\n    ds = ds.apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\\n    ds = ds.str.join(' ')\\n    return ds\\n\\ndf['text_combined'] = text_preprocess(df['text_combined'])\\n\\ndf.to_csv('processed/processed_text2.csv', index=False)\\n\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def text_preprocess(ds: pd.Series) -> pd.Series:\n",
    "    ds = ds.str.lower()\n",
    "    ds = ds.str.replace(r'[^a-zA-Z\\s]+', '', regex=True)\n",
    "    ds = ds.str.split()\n",
    "    ds = ds.apply(lambda x: [word for word in x if word not in stopwords.words('english')])\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    ds = ds.apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "    ds = ds.str.join(' ')\n",
    "    return ds\n",
    "\n",
    "df['text_combined'] = text_preprocess(df['text_combined'])\n",
    "\n",
    "df.to_csv('processed/processed_text2.csv', index=False)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_combined</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hpl nom may see attached file hplno xl hplno xl</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nom actual vols th forwarded sabrae zajac hou ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>enron actuals march april estimated actuals ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hpl nom may see attached file hplno xl hplno xl</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hpl nom june see attached file hplno xl hplno xl</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hpl nom may see attached file hplno xl hplno xl</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tried get fancy address came back forwarded la...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hpl noms february see attached file hplo xl hp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fw pooling contract template original message ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hpl nom march see attached file hplo xl hplo xl</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fw txu lone star pipeline standard pooling agr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>enron hpl nom december see attached file hplnl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hpl nom may see attached file hplno xl hplno xl</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>enron hpl actuals november teco tap hpl gas da...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>txu noms attached please find txu nomination w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hpl nom april see attached file hplno xl hplno xl</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>spoke person confirms pg e side said brian agr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>noms actual vols eileen gas control record ind...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>hpl nom march see attached file hplno xl hplno xl</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>estimated actuals april estimated actuals teco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        text_combined  label\n",
       "0     hpl nom may see attached file hplno xl hplno xl      0\n",
       "1   nom actual vols th forwarded sabrae zajac hou ...      0\n",
       "2   enron actuals march april estimated actuals ma...      0\n",
       "3     hpl nom may see attached file hplno xl hplno xl      0\n",
       "4    hpl nom june see attached file hplno xl hplno xl      0\n",
       "5     hpl nom may see attached file hplno xl hplno xl      0\n",
       "6   tried get fancy address came back forwarded la...      0\n",
       "7   hpl noms february see attached file hplo xl hp...      0\n",
       "8   fw pooling contract template original message ...      0\n",
       "9     hpl nom march see attached file hplo xl hplo xl      0\n",
       "10  fw txu lone star pipeline standard pooling agr...      0\n",
       "11  enron hpl nom december see attached file hplnl...      0\n",
       "12    hpl nom may see attached file hplno xl hplno xl      0\n",
       "13  enron hpl actuals november teco tap hpl gas da...      0\n",
       "14  txu noms attached please find txu nomination w...      0\n",
       "15  hpl nom april see attached file hplno xl hplno xl      0\n",
       "16  spoke person confirms pg e side said brian agr...      0\n",
       "17  noms actual vols eileen gas control record ind...      0\n",
       "18  hpl nom march see attached file hplno xl hplno xl      0\n",
       "19  estimated actuals april estimated actuals teco...      0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('processed/processed_text2.csv')\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=pd.read_csv('processed_text_number.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_combined'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_combined'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1330)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:09<00:00,  8.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6808 clusters of similar texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing clusters: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6808/6808 [00:00<00:00, 682803.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example Cluster 1527:\n",
      "  Entry 1: let go get stoned ethnobotanical herbalist brought herba supplementals kathmandu temple kiff temple ...\n",
      "  Entry 2: legal herb anytime open seven day week call ethnobotanical herbalist brought herba supplementals kat...\n",
      "\n",
      "Example Cluster 2302:\n",
      "  Entry 1: gerry carr mmeddwqshgmailcom certainly sound possible leon let face hang good buddy seem remember ge...\n",
      "  Entry 2: aileen ltfarovpfeircomnet lost pair blue rim brown lens oct gerry carr wrote certainly sound possibl...\n",
      "\n",
      "Example Cluster 2354:\n",
      "  Entry 1: damien domain infoquantumdreamcom trying find cheap chemist shop wont find better range good site ev...\n",
      "  Entry 2: hewitt gino castroddwebpunditscom searching good chemist shop wont find better solution site everyth...\n",
      "  Entry 3: alfie adolphus fortunajeceosuedu trying find cheap chemist shop wont find better assortment site eve...\n",
      "  ... and 15 more entries\n",
      "\n",
      "Example Cluster 4332:\n",
      "  Entry 1: phillip j eby moetelecommunitycom zooko wrote mar pm chris mcdonough wrote zooko wrote httpmailpytho...\n",
      "  Entry 2: chris mcdonough cftxxcplopecom zooko wrote mar pm chris mcdonough wrote zooko wrote httpmailpythonor...\n",
      "\n",
      "Example Cluster 5125:\n",
      "  Entry 1: chris dibona tdfgsdugooglecom see plus pro version would like view imagry chris nov cindytry wrote w...\n",
      "  Entry 2: janda tjzpsqgmailcom google earth open source software world wind nasa open source sw nov pm cindytr...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "def process_chunk(chunk, vectorizer, similarity_threshold=0.9):\n",
    "    tfidf_matrix = vectorizer.transform(chunk['text_combined'])\n",
    "    \n",
    "    sim_matrix = cosine_similarity(tfidf_matrix)\n",
    "    np.fill_diagonal(sim_matrix, 0)  # Zero out self-similarities\n",
    "    \n",
    "    clusters = []\n",
    "    used_indices = set()\n",
    "    \n",
    "    for i in range(len(chunk)):\n",
    "        if i not in used_indices:\n",
    "            similar = np.where(sim_matrix[i] > similarity_threshold)[0]\n",
    "            if len(similar) > 1:\n",
    "                cluster = [chunk.index[idx] for idx in similar]\n",
    "                clusters.append(cluster)\n",
    "                used_indices.update(similar)\n",
    "    \n",
    "    return clusters\n",
    "\n",
    "def handle_similar_texts(df, similarity_threshold=0.9, chunk_size=1000, display_clusters=True, max_clusters_to_show=5):\n",
    "    vectorizer = TfidfVectorizer(max_features=10000)  # Limit features to save memory\n",
    "    vectorizer.fit(df['text_combined'])\n",
    "    \n",
    "    all_clusters = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(df), chunk_size), desc=\"Processing chunks\"):\n",
    "        chunk = df.iloc[i:i+chunk_size]\n",
    "        clusters = process_chunk(chunk, vectorizer, similarity_threshold)\n",
    "        all_clusters.extend(clusters)\n",
    "    \n",
    "    print(f\"Found {len(all_clusters)} clusters of similar texts\")\n",
    "    \n",
    "    # Randomly select a few clusters to display\n",
    "    clusters_to_show = random.sample(all_clusters, min(max_clusters_to_show, len(all_clusters)))\n",
    "    \n",
    "    indices_to_keep = set(df.index)  # Start with all indices\n",
    "    \n",
    "    for i, cluster in enumerate(tqdm(all_clusters, desc=\"Processing clusters\")):\n",
    "        if display_clusters and cluster in clusters_to_show:\n",
    "            print(f\"\\nExample Cluster {i+1}:\")\n",
    "            for j, idx in enumerate(cluster[:3]):  # Show only first 3 entries in the cluster\n",
    "                print(f\"  Entry {j+1}: {df.loc[idx, 'text_combined'][:100]}...\")  # Show only first 100 characters\n",
    "            if len(cluster) > 3:\n",
    "                print(f\"  ... and {len(cluster) - 3} more entries\")\n",
    "        \n",
    "        # Keep only the first entry in the cluster\n",
    "        indices_to_keep -= set(cluster[1:])\n",
    "    \n",
    "    # Keep only the rows we want to keep\n",
    "    df = df.loc[list(indices_to_keep)]\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the function to your dataframe\n",
    "df = handle_similar_texts(df, similarity_threshold=0.6, chunk_size=1000, display_clusters=True, max_clusters_to_show=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_combined</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hpl nom may see attached file hplno xl hplno xl</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nom actual vols th forwarded sabrae zajac hou ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>enron actuals march april estimated actuals ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hpl nom june see attached file hplno xl hplno xl</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tried get fancy address came back forwarded la...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fw pooling contract template original message ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fw txu lone star pipeline standard pooling agr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>enron hpl actuals november teco tap hpl gas da...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>txu noms attached please find txu nomination w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>spoke person confirms pg e side said brian agr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>noms actual vols eileen gas control record ind...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>estimated actuals april estimated actuals teco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>nom alloc june th agree eileen ponton david av...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>txu contract search anthony daren farmer texas...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>nom vols thru agree eileen ponton david avila ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>tufco deal let look get back asap hakeem ogunb...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>fw txu fuel deal imbalance daren deal listed r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>inter intra gisb enron north america forwarded...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>txu fuel company enter contract txu require en...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>gisb contract intrastate interstate gas mr far...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        text_combined  label\n",
       "0     hpl nom may see attached file hplno xl hplno xl      0\n",
       "1   nom actual vols th forwarded sabrae zajac hou ...      0\n",
       "2   enron actuals march april estimated actuals ma...      0\n",
       "4    hpl nom june see attached file hplno xl hplno xl      0\n",
       "6   tried get fancy address came back forwarded la...      0\n",
       "8   fw pooling contract template original message ...      0\n",
       "10  fw txu lone star pipeline standard pooling agr...      0\n",
       "13  enron hpl actuals november teco tap hpl gas da...      0\n",
       "14  txu noms attached please find txu nomination w...      0\n",
       "16  spoke person confirms pg e side said brian agr...      0\n",
       "17  noms actual vols eileen gas control record ind...      0\n",
       "19  estimated actuals april estimated actuals teco...      0\n",
       "20  nom alloc june th agree eileen ponton david av...      0\n",
       "24  txu contract search anthony daren farmer texas...      0\n",
       "25  nom vols thru agree eileen ponton david avila ...      0\n",
       "28  tufco deal let look get back asap hakeem ogunb...      0\n",
       "32  fw txu fuel deal imbalance daren deal listed r...      0\n",
       "34  inter intra gisb enron north america forwarded...      0\n",
       "35  txu fuel company enter contract txu require en...      0\n",
       "37  gisb contract intrastate interstate gas mr far...      0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60350, 2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing too few words\n",
    "from collections import Counter\n",
    "word_counts = Counter()\n",
    "for text in df['text_combined']:\n",
    "    word_counts.update(text.split())\n",
    "\n",
    "# Step 2: Remove words with a frequency of one\n",
    "words_to_remove = {word for word, count in word_counts.items() if count <=20}\n",
    "\n",
    "# Step 3: Reconstruct the text without the rare words\n",
    "def remove_rare_words(text, words_to_remove):\n",
    "    return ' '.join([word for word in text.split() if word not in words_to_remove])\n",
    "\n",
    "df['text_combined'] = df['text_combined'].apply(lambda text: remove_rare_words(text, words_to_remove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_combined</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hpl nom may see attached file xl xl</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nom actual vols th forwarded sabrae zajac hou ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>enron actuals march april estimated actuals ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hpl nom june see attached file xl xl</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tried get fancy address came back forwarded la...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fw pooling contract template original message ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fw txu lone star pipeline standard pooling agr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>enron hpl actuals november teco tap hpl gas da...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>txu noms attached please find txu nomination w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>spoke person confirms pg e side said brian agr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>noms actual vols eileen gas control record ind...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>estimated actuals april estimated actuals teco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>nom june th agree eileen david avila lsp u tu ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>enron hpl actuals march estimated actual march...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>txu contract search anthony daren farmer texas...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>nom vols thru agree eileen david avila lsp u t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>noms actual vols agree eileen pm david avila l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>tufco deal let look get back asap volume manag...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>fw txu fuel deal imbalance daren deal listed r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>inter intra gisb enron north america forwarded...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        text_combined  label\n",
       "0                 hpl nom may see attached file xl xl      0\n",
       "1   nom actual vols th forwarded sabrae zajac hou ...      0\n",
       "2   enron actuals march april estimated actuals ma...      0\n",
       "4                hpl nom june see attached file xl xl      0\n",
       "6   tried get fancy address came back forwarded la...      0\n",
       "8   fw pooling contract template original message ...      0\n",
       "10  fw txu lone star pipeline standard pooling agr...      0\n",
       "13  enron hpl actuals november teco tap hpl gas da...      0\n",
       "14  txu noms attached please find txu nomination w...      0\n",
       "16  spoke person confirms pg e side said brian agr...      0\n",
       "17  noms actual vols eileen gas control record ind...      0\n",
       "19  estimated actuals april estimated actuals teco...      0\n",
       "20  nom june th agree eileen david avila lsp u tu ...      0\n",
       "21  enron hpl actuals march estimated actual march...      0\n",
       "24  txu contract search anthony daren farmer texas...      0\n",
       "25  nom vols thru agree eileen david avila lsp u t...      0\n",
       "27  noms actual vols agree eileen pm david avila l...      0\n",
       "28  tufco deal let look get back asap volume manag...      0\n",
       "32  fw txu fuel deal imbalance daren deal listed r...      0\n",
       "34  inter intra gisb enron north america forwarded...      0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65914, 2)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of overlapping texts: 0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming df is your DataFrame and 'text_combined' is your text data column\n",
    "# 'label' is your target variable\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text_combined'], df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Verify no overlap in the text data\n",
    "train_texts = set(X_train)\n",
    "test_texts = set(X_test)\n",
    "overlap = train_texts.intersection(test_texts)\n",
    "print(f\"Number of overlapping texts: {len(overlap)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48280, 10000)\n",
      "(12070, 10000)\n"
     ]
    }
   ],
   "source": [
    "# Fit the TF-IDF vectorizer on the training data only\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data using the already fitted vectorizer\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "print(X_train_tfidf.shape)\n",
    "print(X_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      6416\n",
      "           1       0.97      0.98      0.98      5654\n",
      "\n",
      "    accuracy                           0.98     12070\n",
      "   macro avg       0.98      0.98      0.98     12070\n",
      "weighted avg       0.98      0.98      0.98     12070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
