{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import zipfile\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nzip_file = zipfile.ZipFile('archive.zip')\\ndfs = {text_file.filename: pd.read_csv(zip_file.open(text_file.filename))\\n       for text_file in zip_file.infolist()\\n       if text_file.filename.endswith('.csv')}\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('archive/Ling.csv')\n",
    "\n",
    "'''\n",
    "zip_file = zipfile.ZipFile('archive.zip')\n",
    "dfs = {text_file.filename: pd.read_csv(zip_file.open(text_file.filename))\n",
    "       for text_file in zip_file.infolist()\n",
    "       if text_file.filename.endswith('.csv')}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>job posting - apple-iss research center</td>\n",
       "      <td>content - length : 3386 apple-iss research cen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>lang classification grimes , joseph e . and ba...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>query : letter frequencies for text identifica...</td>\n",
       "      <td>i am posting this inquiry for sergei atamas ( ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>risk</td>\n",
       "      <td>a colleague and i are researching the differin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>request book information</td>\n",
       "      <td>earlier this morning i was on the phone with a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             subject  \\\n",
       "0            job posting - apple-iss research center   \n",
       "1                                                NaN   \n",
       "2  query : letter frequencies for text identifica...   \n",
       "3                                               risk   \n",
       "4                           request book information   \n",
       "\n",
       "                                                body  label  \n",
       "0  content - length : 3386 apple-iss research cen...      0  \n",
       "1  lang classification grimes , joseph e . and ba...      0  \n",
       "2  i am posting this inquiry for sergei atamas ( ...      0  \n",
       "3  a colleague and i are researching the differin...      0  \n",
       "4  earlier this morning i was on the phone with a...      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>job posting - apple-iss research center</td>\n",
       "      <td>content - length : 3386 apple-iss research cen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>lang classification grimes , joseph e . and ba...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>query : letter frequencies for text identifica...</td>\n",
       "      <td>i am posting this inquiry for sergei atamas ( ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>risk</td>\n",
       "      <td>a colleague and i are researching the differin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>request book information</td>\n",
       "      <td>earlier this morning i was on the phone with a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2854</th>\n",
       "      <td>win $ 300usd and a cruise !</td>\n",
       "      <td>raquel 's casino , inc . is awarding a cruise ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2855</th>\n",
       "      <td>you have been asked to join kiddin</td>\n",
       "      <td>the list owner of : \" kiddin \" has invited you...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2856</th>\n",
       "      <td>anglicization of composers ' names</td>\n",
       "      <td>judging from the return post , i must have sou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2857</th>\n",
       "      <td>re : 6 . 797 , comparative method : n - ary co...</td>\n",
       "      <td>gotcha ! there are two separate fallacies in t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2858</th>\n",
       "      <td>re : american - english in australia</td>\n",
       "      <td>hello ! i ' m working on a thesis concerning a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2859 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                subject  \\\n",
       "0               job posting - apple-iss research center   \n",
       "1                                                   NaN   \n",
       "2     query : letter frequencies for text identifica...   \n",
       "3                                                  risk   \n",
       "4                              request book information   \n",
       "...                                                 ...   \n",
       "2854                        win $ 300usd and a cruise !   \n",
       "2855                 you have been asked to join kiddin   \n",
       "2856                 anglicization of composers ' names   \n",
       "2857  re : 6 . 797 , comparative method : n - ary co...   \n",
       "2858               re : american - english in australia   \n",
       "\n",
       "                                                   body  label  \n",
       "0     content - length : 3386 apple-iss research cen...      0  \n",
       "1     lang classification grimes , joseph e . and ba...      0  \n",
       "2     i am posting this inquiry for sergei atamas ( ...      0  \n",
       "3     a colleague and i are researching the differin...      0  \n",
       "4     earlier this morning i was on the phone with a...      0  \n",
       "...                                                 ...    ...  \n",
       "2854  raquel 's casino , inc . is awarding a cruise ...      1  \n",
       "2855  the list owner of : \" kiddin \" has invited you...      1  \n",
       "2856  judging from the return post , i must have sou...      0  \n",
       "2857  gotcha ! there are two separate fallacies in t...      0  \n",
       "2858  hello ! i ' m working on a thesis concerning a...      0  \n",
       "\n",
       "[2859 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>job posting - apple-iss research center</td>\n",
       "      <td>content - length : 3386 apple-iss research cen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>lang classification grimes , joseph e . and ba...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>query : letter frequencies for text identifica...</td>\n",
       "      <td>i am posting this inquiry for sergei atamas ( ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>risk</td>\n",
       "      <td>a colleague and i are researching the differin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>request book information</td>\n",
       "      <td>earlier this morning i was on the phone with a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             subject  \\\n",
       "0            job posting - apple-iss research center   \n",
       "1                                                NaN   \n",
       "2  query : letter frequencies for text identifica...   \n",
       "3                                               risk   \n",
       "4                           request book information   \n",
       "\n",
       "                                                body  label  \n",
       "0  content - length : 3386 apple-iss research cen...      0  \n",
       "1  lang classification grimes , joseph e . and ba...      0  \n",
       "2  i am posting this inquiry for sergei atamas ( ...      0  \n",
       "3  a colleague and i are researching the differin...      0  \n",
       "4  earlier this morning i was on the phone with a...      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2859.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.160196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.366852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             label\n",
       "count  2859.000000\n",
       "mean      0.160196\n",
       "std       0.366852\n",
       "min       0.000000\n",
       "25%       0.000000\n",
       "50%       0.000000\n",
       "75%       0.000000\n",
       "max       1.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subject    62\n",
       "body        0\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2859, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(445)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['label']==1].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(2352)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['label']==0].value_counts().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = df['body'].astype(str)\n",
    "email_all = \" \".join(emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#email_all_cloud = WordCloud().generate(email_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nplt.figure(figsize=(10, 8))\\nplt.imshow(email_all_cloud, interpolation='bilinear')\\nplt.axis('off')\\nplt.title('Word Cloud of all Emails')\\nplt.show()\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(email_all_cloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud of all Emails')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_emails = df[df['label']==1]['body'].astype(str)\n",
    "spam_emails_all = \" \".join(spam_emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spam_emails_all_cloud = WordCloud().generate(spam_emails_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nplt.figure(figsize=(10, 8))\\nplt.imshow(spam_emails_all_cloud, interpolation='bilinear')\\nplt.axis('off')\\nplt.title('Word Cloud of Spam Emails')\\nplt.show()\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(spam_emails_all_cloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud of Spam Emails')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_emails = df[df['label']==0]['body'].astype(str)\n",
    "clean_emails_all = \" \".join(clean_emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_emails_all_cloud = WordCloud().generate(clean_emails_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nplt.figure(figsize=(10, 8))\\nplt.imshow(clean_emails_all_cloud, interpolation='bilinear')\\nplt.axis('off')\\nplt.title('Word Cloud of Clean Emails')\\nplt.show()\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(clean_emails_all_cloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud of Clean Emails')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\arasekin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\arasekin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\arasekin\\AppData\\Local\\Temp\\ipykernel_11632\\1471786919.py:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\ndef text_preprocess(ds: pd.Series) -> pd.Series:\\n    ds = ds.str.lower()\\n    ds = ds.str.replace(r'[^a-zA-Z\\\\s]+', '', regex=True)\\n    ds = ds.str.split()\\n    ds = ds.apply(lambda x: [word for word in x if word not in stopwords.words('english')])\\n    lemmatizer = WordNetLemmatizer()\\n    ds = ds.apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\\n    ds = ds.str.join(' ')\\n    return ds\\n\\ndf['body'] = text_preprocess(df['body'])\\n\\ndf.to_csv('processed/processed_text_ling.csv', index=False)\\n\\n\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def text_preprocess(ds: pd.Series) -> pd.Series:\n",
    "    ds = ds.str.lower()\n",
    "    ds = ds.str.replace(r'[^a-zA-Z\\s]+', '', regex=True)\n",
    "    ds = ds.str.split()\n",
    "    ds = ds.apply(lambda x: [word for word in x if word not in stopwords.words('english')])\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    ds = ds.apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "    ds = ds.str.join(' ')\n",
    "    return ds\n",
    "\n",
    "df['body'] = text_preprocess(df['body'])\n",
    "\n",
    "df.to_csv('processed/processed_text_ling.csv', index=False)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>job posting - apple-iss research center</td>\n",
       "      <td>content length appleiss research center u mill...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>query : letter frequencies for text identifica...</td>\n",
       "      <td>posting inquiry sergei atamas satamas umabnet ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>risk</td>\n",
       "      <td>colleague researching differing degree risk pe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>request book information</td>\n",
       "      <td>earlier morning phone friend mine living south...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>call for abstracts : optimality in syntactic t...</td>\n",
       "      <td>content length call paper best good enough wor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>m . a . in scandinavian linguistics</td>\n",
       "      <td>scandinavian linguistics university tromsoe co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>call for papers : linguistics session of the m...</td>\n",
       "      <td>call paper linguistics session midwest modern ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>foreign language in commercials</td>\n",
       "      <td>content length greeting wondering someone iden...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fulbright announcement : please post / dissemi...</td>\n",
       "      <td>fulbright announcement please post disseminate...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gala ' 95 : call for papers</td>\n",
       "      <td>groningen assembly language acquisition univer...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bu conf on language development ' 95 - announc...</td>\n",
       "      <td>th annual boston university conference languag...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>korean software for macintosh</td>\n",
       "      <td>dear sir madam would please send information k...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>simultaneous prepositions and postpositions in...</td>\n",
       "      <td>looking analysis nominal construction language...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sum : imperatives without you subjects</td>\n",
       "      <td>content length summary response query imperati...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>policies</td>\n",
       "      <td>moderator message happy subscriber see linguis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>* * * correction to hellenistic greek announce...</td>\n",
       "      <td>couple day ago send fyi hellenistic greek ling...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>question on audio samples</td>\n",
       "      <td>looking audio sample english speech spoken non...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sexism and language</td>\n",
       "      <td>lydie e meunier latest mean say consider oppre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>teaching english in korea</td>\n",
       "      <td>teaching english korea language center chonnam...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>free</td>\n",
       "      <td>multipart message mime format nextpart bd ffe ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              subject  \\\n",
       "0             job posting - apple-iss research center   \n",
       "1   query : letter frequencies for text identifica...   \n",
       "2                                                risk   \n",
       "3                            request book information   \n",
       "4   call for abstracts : optimality in syntactic t...   \n",
       "5                 m . a . in scandinavian linguistics   \n",
       "6   call for papers : linguistics session of the m...   \n",
       "7                     foreign language in commercials   \n",
       "8   fulbright announcement : please post / dissemi...   \n",
       "9                         gala ' 95 : call for papers   \n",
       "10  bu conf on language development ' 95 - announc...   \n",
       "11                      korean software for macintosh   \n",
       "12  simultaneous prepositions and postpositions in...   \n",
       "13             sum : imperatives without you subjects   \n",
       "14                                           policies   \n",
       "15  * * * correction to hellenistic greek announce...   \n",
       "16                          question on audio samples   \n",
       "17                                sexism and language   \n",
       "18                          teaching english in korea   \n",
       "19                                               free   \n",
       "\n",
       "                                                 body  label  \n",
       "0   content length appleiss research center u mill...      0  \n",
       "1   posting inquiry sergei atamas satamas umabnet ...      0  \n",
       "2   colleague researching differing degree risk pe...      0  \n",
       "3   earlier morning phone friend mine living south...      0  \n",
       "4   content length call paper best good enough wor...      0  \n",
       "5   scandinavian linguistics university tromsoe co...      0  \n",
       "6   call paper linguistics session midwest modern ...      0  \n",
       "7   content length greeting wondering someone iden...      0  \n",
       "8   fulbright announcement please post disseminate...      0  \n",
       "9   groningen assembly language acquisition univer...      0  \n",
       "10  th annual boston university conference languag...      0  \n",
       "11  dear sir madam would please send information k...      0  \n",
       "12  looking analysis nominal construction language...      0  \n",
       "13  content length summary response query imperati...      0  \n",
       "14  moderator message happy subscriber see linguis...      0  \n",
       "15  couple day ago send fyi hellenistic greek ling...      0  \n",
       "16  looking audio sample english speech spoken non...      0  \n",
       "17  lydie e meunier latest mean say consider oppre...      0  \n",
       "18  teaching english korea language center chonnam...      0  \n",
       "19  multipart message mime format nextpart bd ffe ...      1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('processed/processed_text_ling.csv')\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['body'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['body'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(15)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['body'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  5.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22 clusters of similar texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing clusters: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example Cluster 3:\n",
      "  Entry 1: georgetown linguistics society present gls development discourse analysis february georgetown univer...\n",
      "  Entry 2: georgetown linguistics society present gls development discourse analysis february georgetown univer...\n",
      "\n",
      "Example Cluster 8:\n",
      "  Entry 1: sixth workshop large corpus august immediately following acl coling university montreal montreal que...\n",
      "  Entry 2: call paper sixth workshop large corpus august immediately following acl coling university montreal m...\n",
      "\n",
      "Example Cluster 15:\n",
      "  Entry 1: call paper wecol western conference linguistics october arizona state university tempe arizona deadl...\n",
      "  Entry 2: teresa well research assistant dr elly van gelderen arizona state university call paper wecol wester...\n",
      "\n",
      "Example Cluster 17:\n",
      "  Entry 1: call paper syllable typology theory conference representation typology syllable held tuebingen germa...\n",
      "  Entry 2: call paper syllable typology theory conference representation typology syllable held tuebingen germa...\n",
      "\n",
      "Example Cluster 18:\n",
      "  Entry 1: second announcement call paper workshop text speech dialog tsd brno czech republic september worksho...\n",
      "  Entry 2: first announcement call paper workshop text speech dialog tsd brno czech republic september workshop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "def process_chunk(chunk, vectorizer, similarity_threshold=0.9):\n",
    "    tfidf_matrix = vectorizer.transform(chunk['body'])\n",
    "    \n",
    "    sim_matrix = cosine_similarity(tfidf_matrix)\n",
    "    np.fill_diagonal(sim_matrix, 0)  # Zero out self-similarities\n",
    "    \n",
    "    clusters = []\n",
    "    used_indices = set()\n",
    "    \n",
    "    for i in range(len(chunk)):\n",
    "        if i not in used_indices:\n",
    "            similar = np.where(sim_matrix[i] > similarity_threshold)[0]\n",
    "            if len(similar) > 1:\n",
    "                cluster = [chunk.index[idx] for idx in similar]\n",
    "                clusters.append(cluster)\n",
    "                used_indices.update(similar)\n",
    "    \n",
    "    return clusters\n",
    "\n",
    "def handle_similar_texts(df, similarity_threshold=0.9, chunk_size=1000, display_clusters=True, max_clusters_to_show=5):\n",
    "    vectorizer = TfidfVectorizer(max_features=10000)  # Limit features to save memory\n",
    "    vectorizer.fit(df['body'])\n",
    "    \n",
    "    all_clusters = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(df), chunk_size), desc=\"Processing chunks\"):\n",
    "        chunk = df.iloc[i:i+chunk_size]\n",
    "        clusters = process_chunk(chunk, vectorizer, similarity_threshold)\n",
    "        all_clusters.extend(clusters)\n",
    "    \n",
    "    print(f\"Found {len(all_clusters)} clusters of similar texts\")\n",
    "    \n",
    "    # Randomly select a few clusters to display\n",
    "    clusters_to_show = random.sample(all_clusters, min(max_clusters_to_show, len(all_clusters)))\n",
    "    \n",
    "    indices_to_keep = set(df.index)  # Start with all indices\n",
    "    \n",
    "    for i, cluster in enumerate(tqdm(all_clusters, desc=\"Processing clusters\")):\n",
    "        if display_clusters and cluster in clusters_to_show:\n",
    "            print(f\"\\nExample Cluster {i+1}:\")\n",
    "            for j, idx in enumerate(cluster[:3]):  # Show only first 3 entries in the cluster\n",
    "                print(f\"  Entry {j+1}: {df.loc[idx, 'body'][:100]}...\")  # Show only first 100 characters\n",
    "            if len(cluster) > 3:\n",
    "                print(f\"  ... and {len(cluster) - 3} more entries\")\n",
    "        \n",
    "        # Keep only the first entry in the cluster\n",
    "        indices_to_keep -= set(cluster[1:])\n",
    "    \n",
    "    # Keep only the rows we want to keep\n",
    "    df = df.loc[list(indices_to_keep)]\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the function to your dataframe\n",
    "df = handle_similar_texts(df, similarity_threshold=0.9, chunk_size=1000, display_clusters=True, max_clusters_to_show=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>job posting - apple-iss research center</td>\n",
       "      <td>content length appleiss research center u mill...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>query : letter frequencies for text identifica...</td>\n",
       "      <td>posting inquiry sergei atamas satamas umabnet ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>risk</td>\n",
       "      <td>colleague researching differing degree risk pe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>request book information</td>\n",
       "      <td>earlier morning phone friend mine living south...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>call for abstracts : optimality in syntactic t...</td>\n",
       "      <td>content length call paper best good enough wor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>m . a . in scandinavian linguistics</td>\n",
       "      <td>scandinavian linguistics university tromsoe co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>call for papers : linguistics session of the m...</td>\n",
       "      <td>call paper linguistics session midwest modern ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>foreign language in commercials</td>\n",
       "      <td>content length greeting wondering someone iden...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fulbright announcement : please post / dissemi...</td>\n",
       "      <td>fulbright announcement please post disseminate...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gala ' 95 : call for papers</td>\n",
       "      <td>groningen assembly language acquisition univer...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bu conf on language development ' 95 - announc...</td>\n",
       "      <td>th annual boston university conference languag...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>korean software for macintosh</td>\n",
       "      <td>dear sir madam would please send information k...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>simultaneous prepositions and postpositions in...</td>\n",
       "      <td>looking analysis nominal construction language...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sum : imperatives without you subjects</td>\n",
       "      <td>content length summary response query imperati...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>policies</td>\n",
       "      <td>moderator message happy subscriber see linguis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>* * * correction to hellenistic greek announce...</td>\n",
       "      <td>couple day ago send fyi hellenistic greek ling...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>question on audio samples</td>\n",
       "      <td>looking audio sample english speech spoken non...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sexism and language</td>\n",
       "      <td>lydie e meunier latest mean say consider oppre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>teaching english in korea</td>\n",
       "      <td>teaching english korea language center chonnam...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>free</td>\n",
       "      <td>multipart message mime format nextpart bd ffe ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              subject  \\\n",
       "0             job posting - apple-iss research center   \n",
       "1   query : letter frequencies for text identifica...   \n",
       "2                                                risk   \n",
       "3                            request book information   \n",
       "4   call for abstracts : optimality in syntactic t...   \n",
       "5                 m . a . in scandinavian linguistics   \n",
       "6   call for papers : linguistics session of the m...   \n",
       "7                     foreign language in commercials   \n",
       "8   fulbright announcement : please post / dissemi...   \n",
       "9                         gala ' 95 : call for papers   \n",
       "10  bu conf on language development ' 95 - announc...   \n",
       "11                      korean software for macintosh   \n",
       "12  simultaneous prepositions and postpositions in...   \n",
       "13             sum : imperatives without you subjects   \n",
       "14                                           policies   \n",
       "15  * * * correction to hellenistic greek announce...   \n",
       "16                          question on audio samples   \n",
       "17                                sexism and language   \n",
       "18                          teaching english in korea   \n",
       "19                                               free   \n",
       "\n",
       "                                                 body  label  \n",
       "0   content length appleiss research center u mill...      0  \n",
       "1   posting inquiry sergei atamas satamas umabnet ...      0  \n",
       "2   colleague researching differing degree risk pe...      0  \n",
       "3   earlier morning phone friend mine living south...      0  \n",
       "4   content length call paper best good enough wor...      0  \n",
       "5   scandinavian linguistics university tromsoe co...      0  \n",
       "6   call paper linguistics session midwest modern ...      0  \n",
       "7   content length greeting wondering someone iden...      0  \n",
       "8   fulbright announcement please post disseminate...      0  \n",
       "9   groningen assembly language acquisition univer...      0  \n",
       "10  th annual boston university conference languag...      0  \n",
       "11  dear sir madam would please send information k...      0  \n",
       "12  looking analysis nominal construction language...      0  \n",
       "13  content length summary response query imperati...      0  \n",
       "14  moderator message happy subscriber see linguis...      0  \n",
       "15  couple day ago send fyi hellenistic greek ling...      0  \n",
       "16  looking audio sample english speech spoken non...      0  \n",
       "17  lydie e meunier latest mean say consider oppre...      0  \n",
       "18  teaching english korea language center chonnam...      0  \n",
       "19  multipart message mime format nextpart bd ffe ...      1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2760, 3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing too few words\n",
    "from collections import Counter\n",
    "word_counts = Counter()\n",
    "for text in df['body']:\n",
    "    word_counts.update(text.split())\n",
    "\n",
    "# Step 2: Remove words with a frequency of one\n",
    "words_to_remove = {word for word, count in word_counts.items() if count <=5}\n",
    "# Step 3: Reconstruct the text without the rare words\n",
    "def remove_rare_words(text, words_to_remove):\n",
    "    return ' '.join([word for word in text.split() if word not in words_to_remove])\n",
    "\n",
    "df['body'] = df['body'].apply(lambda text: remove_rare_words(text, words_to_remove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>job posting - apple-iss research center</td>\n",
       "      <td>content length research center u million joint...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>query : letter frequencies for text identifica...</td>\n",
       "      <td>posting inquiry sergei ab umd edu research ass...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>risk</td>\n",
       "      <td>colleague researching differing degree risk pe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>request book information</td>\n",
       "      <td>earlier morning phone friend mine living south...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>call for abstracts : optimality in syntactic t...</td>\n",
       "      <td>content length call paper best good enough wor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>m . a . in scandinavian linguistics</td>\n",
       "      <td>scandinavian linguistics university tromsoe co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>call for papers : linguistics session of the m...</td>\n",
       "      <td>call paper linguistics session midwest modern ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>foreign language in commercials</td>\n",
       "      <td>content length greeting wondering someone iden...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fulbright announcement : please post / dissemi...</td>\n",
       "      <td>announcement please post list subject scholar ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gala ' 95 : call for papers</td>\n",
       "      <td>groningen assembly language acquisition univer...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bu conf on language development ' 95 - announc...</td>\n",
       "      <td>th annual boston university conference languag...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>korean software for macintosh</td>\n",
       "      <td>dear sir madam would please send information k...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>simultaneous prepositions and postpositions in...</td>\n",
       "      <td>looking analysis nominal construction language...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sum : imperatives without you subjects</td>\n",
       "      <td>content length summary response query imperati...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>policies</td>\n",
       "      <td>moderator message happy subscriber see linguis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>* * * correction to hellenistic greek announce...</td>\n",
       "      <td>couple day ago send greek linguistics resource...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>question on audio samples</td>\n",
       "      <td>looking audio sample english speech spoken non...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sexism and language</td>\n",
       "      <td>lydie e meunier latest mean say consider oppre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>teaching english in korea</td>\n",
       "      <td>teaching english korea language center chonnam...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>free</td>\n",
       "      <td>message mime format nextpart bd ffe content ty...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              subject  \\\n",
       "0             job posting - apple-iss research center   \n",
       "1   query : letter frequencies for text identifica...   \n",
       "2                                                risk   \n",
       "3                            request book information   \n",
       "4   call for abstracts : optimality in syntactic t...   \n",
       "5                 m . a . in scandinavian linguistics   \n",
       "6   call for papers : linguistics session of the m...   \n",
       "7                     foreign language in commercials   \n",
       "8   fulbright announcement : please post / dissemi...   \n",
       "9                         gala ' 95 : call for papers   \n",
       "10  bu conf on language development ' 95 - announc...   \n",
       "11                      korean software for macintosh   \n",
       "12  simultaneous prepositions and postpositions in...   \n",
       "13             sum : imperatives without you subjects   \n",
       "14                                           policies   \n",
       "15  * * * correction to hellenistic greek announce...   \n",
       "16                          question on audio samples   \n",
       "17                                sexism and language   \n",
       "18                          teaching english in korea   \n",
       "19                                               free   \n",
       "\n",
       "                                                 body  label  \n",
       "0   content length research center u million joint...      0  \n",
       "1   posting inquiry sergei ab umd edu research ass...      0  \n",
       "2   colleague researching differing degree risk pe...      0  \n",
       "3   earlier morning phone friend mine living south...      0  \n",
       "4   content length call paper best good enough wor...      0  \n",
       "5   scandinavian linguistics university tromsoe co...      0  \n",
       "6   call paper linguistics session midwest modern ...      0  \n",
       "7   content length greeting wondering someone iden...      0  \n",
       "8   announcement please post list subject scholar ...      0  \n",
       "9   groningen assembly language acquisition univer...      0  \n",
       "10  th annual boston university conference languag...      0  \n",
       "11  dear sir madam would please send information k...      0  \n",
       "12  looking analysis nominal construction language...      0  \n",
       "13  content length summary response query imperati...      0  \n",
       "14  moderator message happy subscriber see linguis...      0  \n",
       "15  couple day ago send greek linguistics resource...      0  \n",
       "16  looking audio sample english speech spoken non...      0  \n",
       "17  lydie e meunier latest mean say consider oppre...      0  \n",
       "18  teaching english korea language center chonnam...      0  \n",
       "19  message mime format nextpart bd ffe content ty...      1  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2760, 3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of overlapping texts: 3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming df is your DataFrame and 'text_combined' is your text data column\n",
    "# 'label' is your target variable\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['body'], df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Verify no overlap in the text data\n",
    "train_texts = set(X_train)\n",
    "test_texts = set(X_test)\n",
    "overlap = train_texts.intersection(test_texts)\n",
    "print(f\"Number of overlapping texts: {len(overlap)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2208, 100)\n",
      "(552, 100)\n"
     ]
    }
   ],
   "source": [
    "# Fit the TF-IDF vectorizer on the training data only\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=100, ngram_range=(1, 2))\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data using the already fitted vectorizer\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "print(X_train_tfidf.shape)\n",
    "print(X_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       463\n",
      "           1       0.97      0.83      0.90        89\n",
      "\n",
      "    accuracy                           0.97       552\n",
      "   macro avg       0.97      0.91      0.94       552\n",
      "weighted avg       0.97      0.97      0.97       552\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       463\n",
      "           1       0.97      0.87      0.92        89\n",
      "\n",
      "    accuracy                           0.97       552\n",
      "   macro avg       0.97      0.93      0.95       552\n",
      "weighted avg       0.97      0.97      0.97       552\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Train a Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_test_tfidf)\n",
    "\n",
    "# Summarize the effects of all the features\n",
    "shap.summary_plot(shap_values, X_test_tfidf, plot_type=\"bar\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
